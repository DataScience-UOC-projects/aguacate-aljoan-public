{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d2efd73-b18a-4f88-b999-5be17ca796e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique regions: 54\n",
      "region_type\n",
      "Unknown    18249\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Load the avocado dataset\n",
    "df = pd.read_csv('avocado.csv')\n",
    "df.info\n",
    "\n",
    "# Step 1: Get the unique regions\n",
    "unique_regions = df['region'].unique()\n",
    "print(f\"Unique regions: {len(unique_regions)}\")\n",
    "\n",
    "# Initialize geolocator with Nominatim service\n",
    "geolocator = Nominatim(user_agent=\"avocado_region_classifier\")\n",
    "\n",
    "# Use RateLimiter to ensure we don't exceed the query limit (adjust delay if needed)\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Step 2: Function to classify the region based on geopy results\n",
    "def classify_region_geopy(region):\n",
    "    try:\n",
    "        location = geocode(region)\n",
    "        if location:\n",
    "            address = location.raw.get('address', {})\n",
    "            if 'city' in address:\n",
    "                return 'City'\n",
    "            elif 'state' in address:\n",
    "                return 'State'\n",
    "            elif 'region' in address:\n",
    "                return 'Region'\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    except:\n",
    "        return 'Error'\n",
    "\n",
    "# Step 3: Apply geocoding function to unique regions\n",
    "unique_region_types = {region: classify_region_geopy(region) for region in unique_regions}\n",
    "\n",
    "# Step 4: Map the geocoded results back to the original dataframe\n",
    "df['region_type'] = df['region'].map(unique_region_types)\n",
    "\n",
    "# Step 5: Show classification counts and save the updated dataframe\n",
    "print(df['region_type'].value_counts())\n",
    "df.to_csv('avocado_with_region_types.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bceb4d9-426d-47ac-92ae-7e447bb56232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique regions: 54\n",
      "Geocoding Albany: {}\n",
      "Geocoding Atlanta: {}\n",
      "Geocoding Boise: {}\n",
      "Geocoding Boston: {}\n",
      "Geocoding California: {}\n",
      "Geocoding Charlotte: {}\n",
      "Geocoding Chicago: {}\n",
      "Geocoding Columbus: {}\n",
      "Geocoding Denver: {}\n",
      "Geocoding Detroit: {}\n",
      "Geocoding GrandRapids: {}\n",
      "Geocoding Houston: {}\n",
      "Geocoding Indianapolis: {}\n",
      "Geocoding Jacksonville: {}\n",
      "Geocoding LasVegas: {}\n",
      "Geocoding LosAngeles: {}\n",
      "Geocoding Louisville: {}\n",
      "Geocoding Midsouth: {}\n",
      "Geocoding Nashville: {}\n",
      "Geocoding NewYork: {}\n",
      "Geocoding Northeast: {}\n",
      "Geocoding Orlando: {}\n",
      "Geocoding Philadelphia: {}\n",
      "Geocoding Pittsburgh: {}\n",
      "Geocoding Plains: {}\n",
      "Geocoding Portland: {}\n",
      "Geocoding Roanoke: {}\n",
      "Geocoding Sacramento: {}\n",
      "Geocoding SanDiego: {}\n",
      "Geocoding SanFrancisco: {}\n",
      "Geocoding Seattle: {}\n",
      "Geocoding SouthCentral: {}\n",
      "Geocoding Southeast: {}\n",
      "Geocoding Spokane: {}\n",
      "Geocoding StLouis: {}\n",
      "Geocoding Syracuse: {}\n",
      "Geocoding Tampa: {}\n",
      "Geocoding West: {}\n",
      "region_type\n",
      "Unknown    18249\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Load the avocado dataset\n",
    "df = pd.read_csv('avocado.csv')\n",
    "\n",
    "# Step 1: Get the unique regions\n",
    "unique_regions = df['region'].unique()\n",
    "print(f\"Unique regions: {len(unique_regions)}\")\n",
    "\n",
    "# Initialize geolocator with Nominatim service\n",
    "geolocator = Nominatim(user_agent=\"avocado_region_classifier\")\n",
    "\n",
    "# Use RateLimiter to ensure we don't exceed the query limit (adjust delay if needed)\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Step 2: Function to classify the region based on geopy results\n",
    "def classify_region_geopy(region):\n",
    "    try:\n",
    "        location = geocode(region)\n",
    "        if location:\n",
    "            address = location.raw.get('address', {})\n",
    "            print(f\"Geocoding {region}: {address}\")  # Print out the address for debugging\n",
    "            # Check if we have information about city, state, or region\n",
    "            if 'city' in address:\n",
    "                return 'City'\n",
    "            elif 'state' in address:\n",
    "                return 'State'\n",
    "            elif 'country' in address or 'region' in address:\n",
    "                return 'Region'\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {region}: {e}\")\n",
    "        return 'Error'\n",
    "\n",
    "# Step 3: Apply geocoding function to unique regions\n",
    "unique_region_types = {region: classify_region_geopy(region) for region in unique_regions}\n",
    "\n",
    "# Step 4: Map the geocoded results back to the original dataframe\n",
    "df['region_type'] = df['region'].map(unique_region_types)\n",
    "\n",
    "# Step 5: Show classification counts and save the updated dataframe\n",
    "print(df['region_type'].value_counts())\n",
    "df.to_csv('avocado_with_region_types.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b87cb4-666e-4e30-883c-a8fc1c55dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_type\n",
      "City      10478\n",
      "Region     6757\n",
      "State       676\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the avocado dataset\n",
    "df = pd.read_csv('avocado.csv')\n",
    "\n",
    "# Step 1: Define the unique regions and manually classify them\n",
    "region_classification = {\n",
    "    'Albany': 'City',\n",
    "    'Atlanta': 'City',\n",
    "    'BaltimoreWashington': 'Region',\n",
    "    'Boise': 'City',\n",
    "    'Boston': 'City',\n",
    "    'BuffaloRochester': 'Region',\n",
    "    'California': 'State',\n",
    "    'Charlotte': 'City',\n",
    "    'Chicago': 'City',\n",
    "    'CincinnatiDayton': 'Region',\n",
    "    'Columbus': 'City',\n",
    "    'DallasFtWorth': 'Region',\n",
    "    'Denver': 'City',\n",
    "    'Detroit': 'City',\n",
    "    'GrandRapids': 'City',\n",
    "    'GreatLakes': 'Region',\n",
    "    'HarrisburgScranton': 'Region',\n",
    "    'HartfordSpringfield': 'Region',\n",
    "    'Houston': 'City',\n",
    "    'Indianapolis': 'City',\n",
    "    'Jacksonville': 'City',\n",
    "    'LasVegas': 'City',\n",
    "    'LosAngeles': 'City',\n",
    "    'Louisville': 'City',\n",
    "    'MiamiFtLauderdale': 'Region',\n",
    "    'Midsouth': 'Region',\n",
    "    'Nashville': 'City',\n",
    "    'NewOrleansMobile': 'Region',\n",
    "    'NewYork': 'City',\n",
    "    'Northeast': 'Region',\n",
    "    'NorthernNewEngland': 'Region',\n",
    "    'Orlando': 'City',\n",
    "    'Philadelphia': 'City',\n",
    "    'PhoenixTucson': 'Region',\n",
    "    'Pittsburgh': 'City',\n",
    "    'Plains': 'Region',\n",
    "    'Portland': 'City',\n",
    "    'RaleighGreensboro': 'Region',\n",
    "    'RichmondNorfolk': 'Region',\n",
    "    'Roanoke': 'City',\n",
    "    'Sacramento': 'City',\n",
    "    'SanDiego': 'City',\n",
    "    'SanFrancisco': 'City',\n",
    "    'Seattle': 'City',\n",
    "    'SouthCarolina': 'State',\n",
    "    'SouthCentral': 'Region',\n",
    "    'Southeast': 'Region',\n",
    "    'Spokane': 'City',\n",
    "    'StLouis': 'City',\n",
    "    'Syracuse': 'City',\n",
    "    'Tampa': 'City',\n",
    "    'West': 'Region',\n",
    "    'WestTexNewMexico': 'Region'\n",
    "}\n",
    "\n",
    "# Step 2: Map the classification back to the DataFrame\n",
    "df['region_type'] = df['region'].map(region_classification)\n",
    "\n",
    "# Step 3: Show classification counts and save the updated dataframe\n",
    "print(df['region_type'].value_counts())\n",
    "df.to_csv('avocado_with_region_types.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a40c391c-598e-4114-8444-4a9a350988d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region_type               region  count\n",
      "0         City               Albany    338\n",
      "1         City              Atlanta    338\n",
      "2         City                Boise    338\n",
      "3         City               Boston    338\n",
      "4         City            Charlotte    338\n",
      "5         City              Chicago    338\n",
      "6         City             Columbus    338\n",
      "7         City               Denver    338\n",
      "8         City              Detroit    338\n",
      "9         City          GrandRapids    338\n",
      "10        City              Houston    338\n",
      "11        City         Indianapolis    338\n",
      "12        City         Jacksonville    338\n",
      "13        City             LasVegas    338\n",
      "14        City           LosAngeles    338\n",
      "15        City           Louisville    338\n",
      "16        City            Nashville    338\n",
      "17        City              NewYork    338\n",
      "18        City              Orlando    338\n",
      "19        City         Philadelphia    338\n",
      "20        City           Pittsburgh    338\n",
      "21        City             Portland    338\n",
      "22        City              Roanoke    338\n",
      "23        City           Sacramento    338\n",
      "24        City             SanDiego    338\n",
      "25        City         SanFrancisco    338\n",
      "26        City              Seattle    338\n",
      "27        City              Spokane    338\n",
      "28        City              StLouis    338\n",
      "29        City             Syracuse    338\n",
      "30        City                Tampa    338\n",
      "31      Region  BaltimoreWashington    338\n",
      "32      Region     BuffaloRochester    338\n",
      "33      Region     CincinnatiDayton    338\n",
      "34      Region        DallasFtWorth    338\n",
      "35      Region           GreatLakes    338\n",
      "36      Region   HarrisburgScranton    338\n",
      "37      Region  HartfordSpringfield    338\n",
      "38      Region    MiamiFtLauderdale    338\n",
      "39      Region             Midsouth    338\n",
      "40      Region     NewOrleansMobile    338\n",
      "41      Region            Northeast    338\n",
      "42      Region   NorthernNewEngland    338\n",
      "43      Region        PhoenixTucson    338\n",
      "44      Region               Plains    338\n",
      "45      Region    RaleighGreensboro    338\n",
      "46      Region      RichmondNorfolk    338\n",
      "47      Region         SouthCentral    338\n",
      "48      Region            Southeast    338\n",
      "49      Region                 West    338\n",
      "50      Region     WestTexNewMexico    335\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('avocado_with_region_types.csv')\n",
    "\n",
    "# Step 1: Filter only regions and cities\n",
    "df_filtered = df[df['region_type'].isin(['City', 'Region'])]\n",
    "\n",
    "# Step 2: Group by region and city to check for duplicates\n",
    "# We'll count how often each city appears in regions and flag duplicates\n",
    "city_region_counts = df_filtered.groupby(['region_type', 'region']).size().reset_index(name='count')\n",
    "\n",
    "# Step 3: Filter for repeated cities\n",
    "repeated_cities_in_region = city_region_counts[city_region_counts['count'] > 1]\n",
    "\n",
    "# Display the repeated cities\n",
    "print(repeated_cities_in_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da47ca-2e1c-4d4b-bbd3-6a8b31d238d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
